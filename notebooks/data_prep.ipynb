{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš— Predicting Used Car Prices\n",
    "\n",
    "### ðŸ” **Problem Statement**\n",
    "Determine the factors that most strongly influence the sale price of a used car and provide price recommendations that maximize dealership profit while staying competitive in the local market.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’¼ **Business Objective**\n",
    "**Maximize gross profit and inventory turnover** by pricing each vehicle within a data-driven range that reflects what local buyers are willing to pay.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Š **Analytics Objective**\n",
    "Develop a **pricing-assist notebook** that delivers:  \n",
    "1. **Best-guess sale price** (point estimate).  \n",
    "2. **90 % prediction interval** (lower & upper bounds).  \n",
    "3. **Feature-driven explanations** of what drives each estimate.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **Success Criteria**\n",
    "**Mean Absolute Error (MAE) â‰¤ \\$1200** on a hold-out test set.\n",
    "\n",
    "> **Why \\$1200?**  \n",
    "> - Typical gross profit per used car in the U.S. is **\\$1200 â€“ \\$2300**.  \n",
    "> - Keeping MAE at \\$1200 caps pricing error so it never wipes out an average unitâ€™s profit.  \n",
    "> - This threshold corresponds to roughly **5 % MAPE** on an average retail price of \\$25â€“26k, keeping errors within an acceptable profit band."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤” Understanding the Dataset\n",
    "\n",
    "Our dataset contains **426k used-car records** with the following attributes:\n",
    "\n",
    "- **id** â€“ unique listing identifier  \n",
    "- **region** â€“ metro area where the car is listed  \n",
    "- **price** â€“ final transaction price in USD  \n",
    "- **year** â€“ model year of the vehicle  \n",
    "- **manufacturer** â€“ brand (e.g., Ford, Honda)  \n",
    "- **model** â€“ specific vehicle line (e.g., Civic, F-150)  \n",
    "- **condition** â€“ seller-reported condition category  \n",
    "- **cylinders** â€“ engine cylinder count (numeric or string)  \n",
    "- **fuel** â€“ fuel type (gas, diesel, hybrid, etc.)  \n",
    "- **odometer** â€“ mileage reading in miles  \n",
    "- **title_status** â€“ title state (clean, salvage, rebuilt, etc.)  \n",
    "- **transmission** â€“ automatic, manual, or other  \n",
    "- **VIN** â€“ Vehicle Identification Number  \n",
    "- **drive** â€“ drivetrain (FWD, RWD, 4WD/AWD)  \n",
    "- **size** â€“ vehicle size class (compact, full-size, etc.)  \n",
    "- **type** â€“ body style (SUV, sedan, truck, etc.)  \n",
    "- **paint_color** â€“ exterior color  \n",
    "- **state** â€“ U.S. state where listed  \n",
    "\n",
    "### What weâ€™ll do in this step\n",
    "1. **Validate & assess data quality**  \n",
    "   * Check for duplicate `id`/`VIN` entries, missing values, and outliers (e.g., negative prices, zero mileage).  \n",
    "   * Standardize categorical levels and spot obvious typos.\n",
    "2. **Explore initial distributions**  \n",
    "   * Visualize price, year, and odometer histograms.  \n",
    "   * Summarize top manufacturers, models, fuel types, and conditions.\n",
    "3. **Spot early relationships**  \n",
    "   * Quick correlations (price vs. mileage and age).  \n",
    "   * Box plots of price by condition, transmission, and drive type.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DATASET INFO\n",
      "==================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 426880 entries, 0 to 426879\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            426880 non-null  int64  \n",
      " 1   region        426880 non-null  object \n",
      " 2   price         426880 non-null  int64  \n",
      " 3   year          425675 non-null  float64\n",
      " 4   manufacturer  409234 non-null  object \n",
      " 5   model         421603 non-null  object \n",
      " 6   condition     252776 non-null  object \n",
      " 7   cylinders     249202 non-null  object \n",
      " 8   fuel          423867 non-null  object \n",
      " 9   odometer      422480 non-null  float64\n",
      " 10  title_status  418638 non-null  object \n",
      " 11  transmission  424324 non-null  object \n",
      " 12  VIN           265838 non-null  object \n",
      " 13  drive         296313 non-null  object \n",
      " 14  size          120519 non-null  object \n",
      " 15  type          334022 non-null  object \n",
      " 16  paint_color   296677 non-null  object \n",
      " 17  state         426880 non-null  object \n",
      "dtypes: float64(2), int64(2), object(14)\n",
      "memory usage: 58.6+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/vehicles.csv')\n",
    "\n",
    "# Print basic info about the dataset\n",
    "print(\"=\"*50)\n",
    "print(\"DATASET INFO\")\n",
    "print(\"=\"*50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FIRST 5 ROWS\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>VIN</th>\n",
       "      <th>drive</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7222695916</td>\n",
       "      <td>prescott</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>az</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7218891961</td>\n",
       "      <td>fayetteville</td>\n",
       "      <td>11900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7221797935</td>\n",
       "      <td>florida keys</td>\n",
       "      <td>21000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7222270760</td>\n",
       "      <td>worcester / central MA</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7210384030</td>\n",
       "      <td>greensboro</td>\n",
       "      <td>4900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                  region  price  year manufacturer model  \\\n",
       "0  7222695916                prescott   6000   NaN          NaN   NaN   \n",
       "1  7218891961            fayetteville  11900   NaN          NaN   NaN   \n",
       "2  7221797935            florida keys  21000   NaN          NaN   NaN   \n",
       "3  7222270760  worcester / central MA   1500   NaN          NaN   NaN   \n",
       "4  7210384030              greensboro   4900   NaN          NaN   NaN   \n",
       "\n",
       "  condition cylinders fuel  odometer title_status transmission  VIN drive  \\\n",
       "0       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
       "1       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
       "2       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
       "3       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
       "4       NaN       NaN  NaN       NaN          NaN          NaN  NaN   NaN   \n",
       "\n",
       "  size type paint_color state  \n",
       "0  NaN  NaN         NaN    az  \n",
       "1  NaN  NaN         NaN    ar  \n",
       "2  NaN  NaN         NaN    fl  \n",
       "3  NaN  NaN         NaN    ma  \n",
       "4  NaN  NaN         NaN    nc  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"FIRST 5 ROWS\")\n",
    "print(\"=\"*50)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the `NaNs` situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NULL VALUES PERCENTAGE BY FEATURE (DESCENDING ORDER)\n",
      "============================================================\n",
      "size            | 306,361 nulls |  71.77%\n",
      "cylinders       | 177,678 nulls |  41.62%\n",
      "condition       | 174,104 nulls |  40.79%\n",
      "VIN             | 161,042 nulls |  37.73%\n",
      "drive           | 130,567 nulls |  30.59%\n",
      "paint_color     | 130,203 nulls |  30.50%\n",
      "type            |  92,858 nulls |  21.75%\n",
      "manufacturer    |  17,646 nulls |   4.13%\n",
      "title_status    |   8,242 nulls |   1.93%\n",
      "model           |   5,277 nulls |   1.24%\n",
      "odometer        |   4,400 nulls |   1.03%\n",
      "fuel            |   3,013 nulls |   0.71%\n",
      "transmission    |   2,556 nulls |   0.60%\n",
      "year            |   1,205 nulls |   0.28%\n",
      "id              |       0 nulls |   0.00%\n",
      "region          |       0 nulls |   0.00%\n",
      "price           |       0 nulls |   0.00%\n",
      "state           |       0 nulls |   0.00%\n",
      "\n",
      "Total dataset size: 426,880 records\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of null values for each feature\n",
    "null_percentages = (df.isnull().sum() / len(df) * 100).sort_values(ascending=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NULL VALUES PERCENTAGE BY FEATURE (DESCENDING ORDER)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for feature, null_pct in null_percentages.items():\n",
    "    null_count = df[feature].isnull().sum()\n",
    "    print(f\"{feature:<15} | {null_count:>7,} nulls | {null_pct:>6.2f}%\")\n",
    "\n",
    "print(f\"\\nTotal dataset size: {len(df):,} records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 features with significant NaNs\n",
    "\n",
    "Based on the table above, there are 7 features with significant amounts of missing info:\n",
    "- size: suggest dropping (values aren't very useful for pricing prediction). âŒ Drop feature\n",
    "- cylinders: probably not highly important. âŒ Drop feature\n",
    "- condition: critical feature to predict price. âœ… Keep\n",
    "- VIN: Drop this feature, not  relevant for pricing model. âŒ Drop feature\n",
    "- drive: suggest dropping (values not very useful for pricing). âŒ Drop feature\n",
    "- paint_color: probably an important feature. âœ… Keep\n",
    "- type: probably an important feature. âœ… Keep\n",
    "\n",
    "Lets check the values of the 3 relevant features with NaNs: `condition`, `paint_color`, `type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VALUE COUNTS FOR 'CONDITION' COLUMN\n",
      "======================================================================\n",
      "Non-null records: 252,776 out of 426,880 total records\n",
      "Null percentage: 40.79%\n",
      "\n",
      "Top 6 values:\n",
      "   1. good                 | 121,456 ( 48.0%)\n",
      "   2. excellent            | 101,467 ( 40.1%)\n",
      "   3. like new             | 21,178 (  8.4%)\n",
      "   4. fair                 |  6,769 (  2.7%)\n",
      "   5. new                  |  1,305 (  0.5%)\n",
      "   6. salvage              |    601 (  0.2%)\n",
      "\n",
      "Total unique values: 6\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze value counts for 'condition' column\n",
    "result = utils.analyze_column(df, 'condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VALUE COUNTS FOR 'PAINT_COLOR' COLUMN\n",
      "======================================================================\n",
      "Non-null records: 296,677 out of 426,880 total records\n",
      "Null percentage: 30.50%\n",
      "\n",
      "Top 10 values:\n",
      "   1. white                | 79,285 ( 26.7%)\n",
      "   2. black                | 62,861 ( 21.2%)\n",
      "   3. silver               | 42,970 ( 14.5%)\n",
      "   4. blue                 | 31,223 ( 10.5%)\n",
      "   5. red                  | 30,473 ( 10.3%)\n",
      "   6. grey                 | 24,416 (  8.2%)\n",
      "   7. green                |  7,343 (  2.5%)\n",
      "   8. custom               |  6,700 (  2.3%)\n",
      "   9. brown                |  6,593 (  2.2%)\n",
      "  10. yellow               |  2,142 (  0.7%)\n",
      "  ... and 2 more unique values\n",
      "\n",
      "Total unique values: 12\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze value counts for 'paint_color' column\n",
    "result = utils.analyze_column(df, 'paint_color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VALUE COUNTS FOR 'TYPE' COLUMN\n",
      "======================================================================\n",
      "Non-null records: 334,022 out of 426,880 total records\n",
      "Null percentage: 21.75%\n",
      "\n",
      "Top 10 values:\n",
      "   1. sedan                | 87,056 ( 26.1%)\n",
      "   2. SUV                  | 77,284 ( 23.1%)\n",
      "   3. pickup               | 43,510 ( 13.0%)\n",
      "   4. truck                | 35,279 ( 10.6%)\n",
      "   5. other                | 22,110 (  6.6%)\n",
      "   6. coupe                | 19,204 (  5.7%)\n",
      "   7. hatchback            | 16,598 (  5.0%)\n",
      "   8. wagon                | 10,751 (  3.2%)\n",
      "   9. van                  |  8,548 (  2.6%)\n",
      "  10. convertible          |  7,731 (  2.3%)\n",
      "  ... and 3 more unique values\n",
      "\n",
      "Total unique values: 13\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze value counts for 'type' column\n",
    "result = utils.analyze_column(df, 'type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Conclusion:** the values of the 3 columns `condition`, `paint_color`, `type` look like great candidates for a pricing model! Because of this, we will move forward by *including these columns*, and filling up the NaNs with `missing` value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CREATING CLEANED DATAFRAME\n",
      "======================================================================\n",
      "Dropped columns: ['size', 'cylinders', 'VIN', 'drive']\n",
      "year            |   1,205 rows with nulls removed\n",
      "odometer        |   4,400 rows with nulls removed\n",
      "\n",
      "Total rows removed: 5,536\n"
     ]
    }
   ],
   "source": [
    "# Create cleaned dataframe with dropna for year/odometer\n",
    "print(\"=\"*70)\n",
    "print(\"CREATING CLEANED DATAFRAME\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Drop unwanted columns\n",
    "columns_to_drop = ['size', 'cylinders', 'VIN', 'drive']\n",
    "df_cars = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"Dropped columns: {columns_to_drop}\")\n",
    "\n",
    "# Step 2: Remove rows with missing year/odometer first\n",
    "rows_before = len(df_cars)\n",
    "year_nulls = df_cars['year'].isnull().sum()\n",
    "odometer_nulls = df_cars['odometer'].isnull().sum()\n",
    "\n",
    "# Remove rows with missing year or odometer\n",
    "df_cars = df_cars.dropna(subset=['year', 'odometer'])\n",
    "\n",
    "rows_after = len(df_cars)\n",
    "rows_removed = rows_before - rows_after\n",
    "\n",
    "print(f\"year            | {year_nulls:>7,} rows with nulls removed\")\n",
    "print(f\"odometer        | {odometer_nulls:>7,} rows with nulls removed\")\n",
    "print(f\"\\nTotal rows removed: {rows_removed:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "APPLYING 'MISSING' CATEGORY TO CATEGORICAL NULL VALUES\n",
      "==================================================\n",
      "region          |       0 nulls filled with 'missing'\n",
      "manufacturer    |  16,267 nulls filled with 'missing'\n",
      "model           |   5,195 nulls filled with 'missing'\n",
      "condition       | 170,493 nulls filled with 'missing'\n",
      "fuel            |   2,172 nulls filled with 'missing'\n",
      "title_status    |   7,358 nulls filled with 'missing'\n",
      "transmission    |   1,695 nulls filled with 'missing'\n",
      "type            |  91,782 nulls filled with 'missing'\n",
      "paint_color     | 128,090 nulls filled with 'missing'\n",
      "state           |       0 nulls filled with 'missing'\n",
      "\n",
      "==================================================\n",
      "FINAL CLEANED DATAFRAME SUMMARY\n",
      "==================================================\n",
      "Final shape: (421344, 14)\n",
      "Total remaining null values: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Apply \"missing\" category to categorical features\n",
    "print(f\"{'='*50}\")\n",
    "print(\"APPLYING 'MISSING' CATEGORY TO CATEGORICAL NULL VALUES\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Handle categorical columns (object type)\n",
    "categorical_cols = df_cars.select_dtypes(include=['object']).columns.tolist()\n",
    "# Remove id from categorical processing\n",
    "categorical_cols = [col for col in categorical_cols if col not in ['id']]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    null_count_before = df_cars[col].isnull().sum()\n",
    "    df_cars[col] = df_cars[col].fillna('missing')\n",
    "    print(f\"{col:<15} | {null_count_before:>7,} nulls filled with 'missing'\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"FINAL CLEANED DATAFRAME SUMMARY\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Final shape: {df_cars.shape}\")\n",
    "\n",
    "# Check for any remaining nulls\n",
    "remaining_nulls = df_cars.isnull().sum().sum()\n",
    "print(f\"Total remaining null values: {remaining_nulls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FIRST 5 ROWS OF CLEANED DATA\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>condition</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7316814884</td>\n",
       "      <td>auburn</td>\n",
       "      <td>33590</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>gmc</td>\n",
       "      <td>sierra 1500 crew cab slt</td>\n",
       "      <td>good</td>\n",
       "      <td>gas</td>\n",
       "      <td>57923.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>pickup</td>\n",
       "      <td>white</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7316814758</td>\n",
       "      <td>auburn</td>\n",
       "      <td>22590</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>silverado 1500</td>\n",
       "      <td>good</td>\n",
       "      <td>gas</td>\n",
       "      <td>71229.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>pickup</td>\n",
       "      <td>blue</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7316814989</td>\n",
       "      <td>auburn</td>\n",
       "      <td>39590</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>silverado 1500 crew</td>\n",
       "      <td>good</td>\n",
       "      <td>gas</td>\n",
       "      <td>19160.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>pickup</td>\n",
       "      <td>red</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7316743432</td>\n",
       "      <td>auburn</td>\n",
       "      <td>30990</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>toyota</td>\n",
       "      <td>tundra double cab sr</td>\n",
       "      <td>good</td>\n",
       "      <td>gas</td>\n",
       "      <td>41124.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>pickup</td>\n",
       "      <td>red</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7316356412</td>\n",
       "      <td>auburn</td>\n",
       "      <td>15000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>f-150 xlt</td>\n",
       "      <td>excellent</td>\n",
       "      <td>gas</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>truck</td>\n",
       "      <td>black</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  region  price    year manufacturer                     model  \\\n",
       "27  7316814884  auburn  33590  2014.0          gmc  sierra 1500 crew cab slt   \n",
       "28  7316814758  auburn  22590  2010.0    chevrolet            silverado 1500   \n",
       "29  7316814989  auburn  39590  2020.0    chevrolet       silverado 1500 crew   \n",
       "30  7316743432  auburn  30990  2017.0       toyota      tundra double cab sr   \n",
       "31  7316356412  auburn  15000  2013.0         ford                 f-150 xlt   \n",
       "\n",
       "    condition fuel  odometer title_status transmission    type paint_color  \\\n",
       "27       good  gas   57923.0        clean        other  pickup       white   \n",
       "28       good  gas   71229.0        clean        other  pickup        blue   \n",
       "29       good  gas   19160.0        clean        other  pickup         red   \n",
       "30       good  gas   41124.0        clean        other  pickup         red   \n",
       "31  excellent  gas  128000.0        clean    automatic   truck       black   \n",
       "\n",
       "   state  \n",
       "27    al  \n",
       "28    al  \n",
       "29    al  \n",
       "30    al  \n",
       "31    al  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{'='*50}\")\n",
    "print(\"FIRST 5 ROWS OF CLEANED DATA\")\n",
    "print(f\"{'='*50}\")\n",
    "df_cars.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¡ Handling issues with high cardinality columns\n",
    "\n",
    "2 columns exhibit high cardinality: `model` and `region`. I will analyze them to decide how to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODEL COLUMN DISTRIBUTION ANALYSIS\n",
      "============================================================\n",
      "Total records in dataset: 421,344\n",
      "Number of distinct models: 29,220\n",
      "Average records per model: 14.4\n",
      "\n",
      "Top 40 most common models (with manufacturer):\n",
      "   1. f-150                     | ford            | 7,870 ( 1.9%)\n",
      "   2. missing                   | N/A             | 5,195 ( 1.2%)\n",
      "   3. silverado 1500            | chevrolet       | 5,043 ( 1.2%)\n",
      "   4. 1500                      | ram             | 4,178 ( 1.0%)\n",
      "   5. camry                     | toyota          | 3,070 ( 0.7%)\n",
      "   6. silverado                 | chevrolet       | 2,991 ( 0.7%)\n",
      "   7. accord                    | honda           | 2,925 ( 0.7%)\n",
      "   8. wrangler                  | jeep            | 2,786 ( 0.7%)\n",
      "   9. civic                     | honda           | 2,775 ( 0.7%)\n",
      "  10. altima                    | nissan          | 2,719 ( 0.6%)\n",
      "  11. escape                    | ford            | 2,709 ( 0.6%)\n",
      "  12. 2500                      | ram             | 2,675 ( 0.6%)\n",
      "  13. tacoma                    | toyota          | 2,528 ( 0.6%)\n",
      "  14. explorer                  | ford            | 2,480 ( 0.6%)\n",
      "  15. grand cherokee            | jeep            | 2,467 ( 0.6%)\n",
      "  16. mustang                   | ford            | 2,210 ( 0.5%)\n",
      "  17. corolla                   | toyota          | 2,196 ( 0.5%)\n",
      "  18. equinox                   | chevrolet       | 1,938 ( 0.5%)\n",
      "  19. fusion                    | ford            | 1,924 ( 0.5%)\n",
      "  20. cr-v                      | honda           | 1,899 ( 0.5%)\n",
      "  21. focus                     | ford            | 1,787 ( 0.4%)\n",
      "  22. malibu                    | chevrolet       | 1,735 ( 0.4%)\n",
      "  23. charger                   | dodge           | 1,692 ( 0.4%)\n",
      "  24. tahoe                     | chevrolet       | 1,688 ( 0.4%)\n",
      "  25. rav4                      | toyota          | 1,661 ( 0.4%)\n",
      "  26. sonata                    | hyundai         | 1,658 ( 0.4%)\n",
      "  27. corvette                  | chevrolet       | 1,655 ( 0.4%)\n",
      "  28. impala                    | chevrolet       | 1,638 ( 0.4%)\n",
      "  29. sierra 1500               | gmc             | 1,619 ( 0.4%)\n",
      "  30. grand caravan             | dodge           | 1,585 ( 0.4%)\n",
      "  31. outback                   | subaru          | 1,537 ( 0.4%)\n",
      "  32. silverado 2500hd          | chevrolet       | 1,529 ( 0.4%)\n",
      "  33. cruze                     | chevrolet       | 1,526 ( 0.4%)\n",
      "  34. f-250                     | ford            | 1,522 ( 0.4%)\n",
      "  35. 3500                      | ram             | 1,483 ( 0.4%)\n",
      "  36. elantra                   | hyundai         | 1,478 ( 0.4%)\n",
      "  37. odyssey                   | honda           | 1,474 ( 0.3%)\n",
      "  38. edge                      | ford            | 1,452 ( 0.3%)\n",
      "  39. prius                     | toyota          | 1,421 ( 0.3%)\n",
      "  40. tundra                    | toyota          | 1,402 ( 0.3%)\n",
      "\n",
      "Top 40 models cover 94,120 records (22.3% of dataset)\n",
      "\n",
      "Distribution by frequency thresholds:\n",
      "Models appearing exactly 1 time: 15,146\n",
      "Models appearing 10+ times: 4,347\n",
      "Models appearing 100+ times: 656\n",
      "Models appearing 1000+ times: 58\n"
     ]
    }
   ],
   "source": [
    "# Analyze model column using utility function\n",
    "model_analysis = utils.analyze_categorical_distribution(df_cars, 'model', top_n=40, related_column='manufacturer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `model` column has ~30k distinct values. So, one-hot encoding them won't work. I've decided to **keep the top 50 models** (remaining ones will be set to `other_<manufacturer>`). These top 40 cover 22% of the dataset (meaning: for the remaining less popular ~78% models we will lose predictive power)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "REGION COLUMN DISTRIBUTION ANALYSIS\n",
      "============================================================\n",
      "Total records in dataset: 421,344\n",
      "Number of distinct regions: 404\n",
      "Average records per region: 1042.9\n",
      "\n",
      "Top 40 most common regions (with state):\n",
      "   1. columbus                  | oh              | 3,608 ( 0.9%)\n",
      "   2. jacksonville              | fl              | 3,522 ( 0.8%)\n",
      "   3. spokane / coeur d'alene   | id              | 2,985 ( 0.7%)\n",
      "   4. new hampshire             | nh              | 2,979 ( 0.7%)\n",
      "   5. sarasota-bradenton        | fl              | 2,975 ( 0.7%)\n",
      "   6. south jersey              | nj              | 2,973 ( 0.7%)\n",
      "   7. eugene                    | or              | 2,973 ( 0.7%)\n",
      "   8. grand rapids              | mi              | 2,972 ( 0.7%)\n",
      "   9. pittsburgh                | pa              | 2,970 ( 0.7%)\n",
      "  10. houston                   | tx              | 2,969 ( 0.7%)\n",
      "  11. nashville                 | tn              | 2,969 ( 0.7%)\n",
      "  12. philadelphia              | pa              | 2,967 ( 0.7%)\n",
      "  13. rochester                 | ny              | 2,967 ( 0.7%)\n",
      "  14. maine                     | me              | 2,966 ( 0.7%)\n",
      "  15. tulsa                     | ok              | 2,966 ( 0.7%)\n",
      "  16. milwaukee                 | wi              | 2,965 ( 0.7%)\n",
      "  17. reno / tahoe              | ca              | 2,964 ( 0.7%)\n",
      "  18. baltimore                 | md              | 2,964 ( 0.7%)\n",
      "  19. north jersey              | nj              | 2,962 ( 0.7%)\n",
      "  20. stockton                  | ca              | 2,957 ( 0.7%)\n",
      "  21. boise                     | id              | 2,956 ( 0.7%)\n",
      "  22. detroit metro             | mi              | 2,956 ( 0.7%)\n",
      "  23. kansas city, MO           | ks              | 2,955 ( 0.7%)\n",
      "  24. long island               | ny              | 2,954 ( 0.7%)\n",
      "  25. kennewick-pasco-richland  | wa              | 2,952 ( 0.7%)\n",
      "  26. central NJ                | nj              | 2,950 ( 0.7%)\n",
      "  27. washington, DC            | dc              | 2,946 ( 0.7%)\n",
      "  28. cleveland                 | oh              | 2,946 ( 0.7%)\n",
      "  29. minneapolis / st paul     | mn              | 2,946 ( 0.7%)\n",
      "  30. orlando                   | fl              | 2,945 ( 0.7%)\n",
      "  31. austin                    | tx              | 2,943 ( 0.7%)\n",
      "  32. new york city             | ny              | 2,943 ( 0.7%)\n",
      "  33. sacramento                | ca              | 2,940 ( 0.7%)\n",
      "  34. st louis, MO              | il              | 2,940 ( 0.7%)\n",
      "  35. tampa bay area            | fl              | 2,936 ( 0.7%)\n",
      "  36. SF bay area               | ca              | 2,935 ( 0.7%)\n",
      "  37. albuquerque               | nm              | 2,935 ( 0.7%)\n",
      "  38. phoenix                   | az              | 2,932 ( 0.7%)\n",
      "  39. boston                    | ma              | 2,928 ( 0.7%)\n",
      "  40. hawaii                    | hi              | 2,924 ( 0.7%)\n",
      "\n",
      "Top 40 regions cover 119,435 records (28.3% of dataset)\n",
      "\n",
      "Distribution by frequency thresholds:\n",
      "Regions appearing exactly 1 time: 0\n",
      "Regions appearing 10+ times: 402\n",
      "Regions appearing 100+ times: 375\n",
      "Regions appearing 1000+ times: 145\n"
     ]
    }
   ],
   "source": [
    "# Analyze region column using utility function\n",
    "model_analysis = utils.analyze_categorical_distribution(df_cars, 'region', top_n=40, related_column='state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `region` column has 404 distinct values. So, one-hot encoding them won't work. I've decided to **keep the top 40 regions** (remaining ones will be set to `other_<state>`). These top 40 cover 28% of the dataset (meaning: for the remaining less popular ~72% regions we will lose predictive power)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying the dataframe by reducing cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SIMPLIFYING 'MODEL' COLUMN (TOP 40)\n",
      "============================================================\n",
      "Top 40 models identified: 40 values\n",
      "Top 10 models: ['f-150', 'missing', 'silverado 1500', '1500', 'camry', 'silverado', 'accord', 'wrangler', 'civic', 'altima'] ... (and 30 more)\n",
      "\n",
      "Original unique models: 29,220\n",
      "Simplified unique models: 82\n",
      "Reduction: 29,138 values (99.7%)\n",
      "\n",
      "New model distribution (top 15):\n",
      "   1. other_ford                     | 47,650 (11.3%)\n",
      "   2. other_chevrolet                | 33,365 ( 7.9%)\n",
      "   3. other_toyota                   | 21,257 ( 5.0%)\n",
      "   4. other_missing                  | 16,233 ( 3.9%)\n",
      "   5. other_nissan                   | 15,978 ( 3.8%)\n",
      "   6. other_gmc                      | 14,678 ( 3.5%)\n",
      "   7. other_bmw                      | 14,494 ( 3.4%)\n",
      "   8. other_jeep                     | 13,420 ( 3.2%)\n",
      "   9. other_honda                    | 11,840 ( 2.8%)\n",
      "  10. other_mercedes-benz            | 11,474 ( 2.7%)\n",
      "  11. other_dodge                    |  9,959 ( 2.4%)\n",
      "  12. other_ram                      |  9,490 ( 2.3%)\n",
      "  13. other_volkswagen               |  9,167 ( 2.2%)\n",
      "  14. other_kia                      |  8,310 ( 2.0%)\n",
      "  15. other_lexus                    |  8,082 ( 1.9%)\n"
     ]
    }
   ],
   "source": [
    "# Start with a copy of the cleaned dataframe\n",
    "df_cars_simplified = df_cars.copy()\n",
    "\n",
    "# Process the 'model' column using the utility function\n",
    "df_cars_simplified['model'] = utils.simplify_high_cardinality_column(\n",
    "    df_cars_simplified, \n",
    "    target_column='model', \n",
    "    related_column='manufacturer', \n",
    "    top_n=40\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SIMPLIFYING 'REGION' COLUMN (TOP 40)\n",
      "============================================================\n",
      "Top 40 regions identified: 40 values\n",
      "Top 10 regions: ['columbus', 'jacksonville', \"spokane / coeur d'alene\", 'new hampshire', 'sarasota-bradenton', 'south jersey', 'eugene', 'grand rapids', 'pittsburgh', 'houston'] ... (and 30 more)\n",
      "\n",
      "Original unique regions: 404\n",
      "Simplified unique regions: 87\n",
      "Reduction: 317 values (78.5%)\n",
      "\n",
      "New region distribution (top 15):\n",
      "   1. other_ca                       | 37,652 ( 8.9%)\n",
      "   2. other_tx                       | 16,799 ( 4.0%)\n",
      "   3. other_fl                       | 16,340 ( 3.9%)\n",
      "   4. other_nc                       | 14,198 ( 3.4%)\n",
      "   5. other_or                       | 13,759 ( 3.3%)\n",
      "   6. other_oh                       | 11,722 ( 2.8%)\n",
      "   7. other_ny                       | 11,135 ( 2.6%)\n",
      "   8. other_mi                       | 10,932 ( 2.6%)\n",
      "   9. other_co                       | 10,926 ( 2.6%)\n",
      "  10. other_va                       | 10,511 ( 2.5%)\n",
      "  11. other_wa                       | 10,400 ( 2.5%)\n",
      "  12. other_wi                       |  8,355 ( 2.0%)\n",
      "  13. other_ia                       |  8,192 ( 1.9%)\n",
      "  14. other_tn                       |  8,066 ( 1.9%)\n",
      "  15. other_pa                       |  7,689 ( 1.8%)\n"
     ]
    }
   ],
   "source": [
    "# Process the 'model' column using the utility function\n",
    "df_cars_simplified['region'] = utils.simplify_high_cardinality_column(\n",
    "    df_cars_simplified, \n",
    "    target_column='region', \n",
    "    related_column='state', \n",
    "    top_n=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL PROCESSED DATAFRAME SUMMARY\n",
      "============================================================\n",
      "Final shape: (421344, 14)\n",
      "Features: ['id', 'region', 'price', 'year', 'manufacturer', 'model', 'condition', 'fuel', 'odometer', 'title_status', 'transmission', 'type', 'paint_color', 'state']\n",
      "\n",
      "Sample of simplified high-cardinality columns:\n",
      "Unique models: 82\n",
      "Unique regions: 87\n",
      "\n",
      "============================================================\n",
      "EXPORTING TO CSV\n",
      "============================================================\n",
      "âœ… Successfully exported 421,344 records to '../data/vehicles_processed.csv'\n",
      "   File size: 237.8 MB in memory\n",
      "   Ready for modeling! ðŸš—\n"
     ]
    }
   ],
   "source": [
    "df_cars_processed = df_cars_simplified.copy()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL PROCESSED DATAFRAME SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final shape: {df_cars_processed.shape}\")\n",
    "print(f\"Features: {list(df_cars_processed.columns)}\")\n",
    "print(f\"\\nSample of simplified high-cardinality columns:\")\n",
    "print(f\"Unique models: {df_cars_processed['model'].nunique()}\")\n",
    "print(f\"Unique regions: {df_cars_processed['region'].nunique()}\")\n",
    "\n",
    "# Export to CSV\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EXPORTING TO CSV\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "output_path = '../data/vehicles_processed.csv'\n",
    "df_cars_processed.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… Successfully exported {len(df_cars_processed):,} records to '{output_path}'\")\n",
    "print(f\"   File size: {df_cars_processed.memory_usage(deep=True).sum() / 1024**2:.1f} MB in memory\")\n",
    "print(f\"   Ready for modeling! ðŸš—\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
